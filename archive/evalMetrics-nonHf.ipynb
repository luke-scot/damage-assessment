{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intellectual-macedonia",
   "metadata": {},
   "source": [
    "# Notebook evaluating metrics for particular node/edge configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rough-clothing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installs \n",
    "#%pip install rioxarray xarray earthpy\n",
    "\n",
    "# Package imports\n",
    "import math\n",
    "import json\n",
    "import requests\n",
    "import os\n",
    "import ipyleaflet\n",
    "import PIL\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import sklearn as skl\n",
    "import rasterio as ro\n",
    "import rioxarray as rxr\n",
    "import xarray as xr\n",
    "#import earthpy as et\n",
    "import seaborn as sns\n",
    "#import earthpy.plot as ep\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.metrics as skm\n",
    "import matplotlib.cm as cm\n",
    "from base64 import b64encode\n",
    "from io import BytesIO\n",
    "from tqdm import tqdm\n",
    "from ipywidgets import HTML\n",
    "from ipyleaflet import Map, basemaps, GeoData, CircleMarker, Popup, GeoJSON, LegendControl, ImageOverlay\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "from sklearn.model_selection import train_test_split\n",
    "from rasterio.plot import show\n",
    "from IPython.display import Image, display\n",
    "from shapely.geometry import Polygon, Point, mapping\n",
    "\n",
    "import descarteslabs as dl\n",
    "import descarteslabs.workflows as wf\n",
    "\n",
    "#import ./netconf.netconf as nc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "listed-holmes",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define variables\n",
    "# Location variables\n",
    "lat, lon, zoom = 33.893, 35.512, 14 # Map properties\n",
    "\n",
    "# Building Footprints variables\n",
    "buildings = \"../data/beirutBuildingFootprints.geojson\"\n",
    "\n",
    "# Damage Assessment variables\n",
    "dataFile = \"../data/geopalData.csv\" # GeoPal data\n",
    "\n",
    "# Interferogram paths\n",
    "ifgPath = \"../data/beirutPrePostExplosionIfg.tif\"\n",
    "croppedPath = \"../data/croppedIfg.png\"\n",
    "\n",
    "# A priori damage beliefs (green, yellow, red decisions)\n",
    "gb, yb, rb = 0, 0.7, 1\n",
    "\n",
    "# Edge creation\n",
    "adjacent, ifgValues, neighbours = True, True, 10\n",
    "\n",
    "# Train/test split\n",
    "testSplit, dmgThresh, stdTest, randomState = 0.3, 0.5, False, 42\n",
    "\n",
    "# Classifications\n",
    "targets = ['Undamaged', 'Damaged']\n",
    "decisions = {'GREEN (inspected) أخضر (تم دراسته)': False, 'YELLOW (restricted use) أصفر (لا يصلح للسكن)': True, 'RED (unsafe/evacuate) أحمر (غير آمن/للاخلاء)ء': True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handled-great",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import Ground Data and combine\n",
    "# Import footprints geojson\n",
    "builds = gpd.read_file(buildings)\n",
    "pd.set_option('display.max_columns', None)\n",
    "fps = gpd.GeoDataFrame(builds[['id','building','name']], geometry=builds.geometry)\n",
    "\n",
    "# Import GeoPal data\n",
    "allData = pd.read_csv(dataFile)\n",
    "# Extract locations from joint column in database\n",
    "locations, mapPoints = allData['get location - الموقع_w_2049198'], allData['point on map - الموقع على الخريطة_w_2049199']\n",
    "lats, lons = np.zeros([len(locations), 1]),  np.zeros([len(locations), 1])\n",
    "for i in range(len(locations)):\n",
    "    loc = locations[i]\n",
    "    if type(loc) is float or (type(loc) is str and loc[0].isalpha()):\n",
    "        mp = mapPoints[i]\n",
    "        if type(mp) is str and mp[0].isdigit():\n",
    "            try: lats[i], lons[i] = mp.split(' ')[0], mp.split(' ')[1]\n",
    "            except: lats[i], lons[i] = mp.split(',')[0], mp.split(',')[1] # Deal with rogue commas instead of space\n",
    "    else: lats[i], lons[i] = loc.split(' ')[0], loc.split(' ')[1]\n",
    "\n",
    "# Extract columns of useful data\n",
    "data = pd.DataFrame({\n",
    "    'id': allData['Job ID'],\n",
    "    'area': allData['plot area - المنطقة العقارية_w_2049201'],\n",
    "    'damage': allData['structural damage level - مستوى الضرر الأنشائي للمبنى_w_2049205'],\n",
    "    'floors': allData['number of floors - عدد الطوابق_w_2049208'],\n",
    "    'units': allData['number of units - عدد الشقق_w_2049209'],\n",
    "    'use': allData['building use - وجهة الاستعمال للمبنى_w_2049210'],\n",
    "    'photos': allData['take pictures - التقاط صور_w_2049222'],\n",
    "    'decision': allData['decision - القرار_w_2049224']    \n",
    "})\n",
    "\n",
    "# Create geodatabase merging locations with useful data\n",
    "assessments = gpd.GeoDataFrame(data, geometry=gpd.points_from_xy(lons, lats),crs={'init': 'epsg:4326'})\n",
    "\n",
    "# Filter for non located values\n",
    "locs = assessments[assessments.geometry.x != 0]\n",
    "\n",
    "# Get joint geodataframe of building footprints with damage assessments\n",
    "joint = gpd.sjoin(fps, locs, how=\"left\", op='contains').dropna(subset=['decision'])\n",
    "\n",
    "def to_geodata(gdf, color):\n",
    "    plotGdf = GeoData(geo_dataframe = gdf,\n",
    "                          style={'color': color, 'radius':2, 'fillColor': color, 'opacity':0.9, 'weight':1.9, 'dashArray':'2', 'fillOpacity':0.7},\n",
    "                          hover_style={'fillColor': 'white' , 'fillOpacity': 0.2},\n",
    "                          point_style={'radius': 3, 'color': color, 'fillOpacity': 0.8, 'fillColor': color, 'weight': 3},\n",
    "                          name = 'Images')\n",
    "    return plotGdf\n",
    "\n",
    "m1 = Map(basemap=basemaps.OpenStreetMap.Mapnik, center=[lat, lon], zoom=zoom, scroll_wheel_zoom=True)\n",
    "m1.add_layer(to_geodata(joint.loc[joint['decision'] == 'GREEN (inspected) أخضر (تم دراسته)'],'green'))\n",
    "m1.add_layer(to_geodata(joint.loc[joint['decision'] == 'YELLOW (restricted use) أصفر (لا يصلح للسكن)'],'yellow'))\n",
    "m1.add_layer(to_geodata(joint.loc[joint['decision'] == 'RED (unsafe/evacuate) أحمر (غير آمن/للاخلاء)ء'],'red'))\n",
    "\n",
    "if not 'l1' in globals(): # Add legend if forming map for first time\n",
    "    l1 = legend = LegendControl({\"No Restrictions\":\"#008000\", \"Restricted Use\":\"#FFFF00\", \"Unsafe/Evacuated\":\"#FF0000\", \"No Decision\":\"#0000FF\"}, name=\"Decision\", position=\"bottomleft\")\n",
    "    m1.add_control(l1)\n",
    "\n",
    "# Display map upon which to draw Polygon for analysis\n",
    "bd = joint.total_bounds\n",
    "testPoly = ipyleaflet.Polygon(locations = [(bd[1]+0.012, bd[0]), (bd[1]+0.012, bd[2]-0.01), (bd[3], bd[2]-0.01),(bd[3], bd[0])], color=\"yellow\", fill_color=\"yellow\", transform=False if stdTest else True)\n",
    "\n",
    "m1.add_layer(testPoly)\n",
    "m1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "useful-florida",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get interferogram data and combine with ground data\n",
    "# Import interferogram\n",
    "wholeIfg = rxr.open_rasterio(ifgPath, masked=True).squeeze()\n",
    "poly = Polygon([[p['lng'], p['lat']] for p in testPoly.locations[0]])\n",
    "extent = gpd.GeoSeries([poly])\n",
    "croppedIfg = wholeIfg.rio.clip(extent.geometry.apply(mapping), extent.crs)\n",
    "\n",
    "# Create nodes\n",
    "named = croppedIfg.rename('ifg')\n",
    "df = named.to_dataframe()\n",
    "coords = np.concatenate(np.array(df.axes[0]))\n",
    "initial = gpd.GeoDataFrame(pd.DataFrame(np.concatenate((np.ones([len(df),2])*0.5, np.array(df['ifg']).reshape(-1,1)), axis=1), columns = ['noDmg','dmg','ifg']), geometry=gpd.points_from_xy(coords[1::2], coords[0::2]),crs={'init': 'epsg:4326'})\n",
    "\n",
    "# Assign updated beliefs to pixels within assessed building footprints\n",
    "X_train, X_test, y_train, y_test = train_test_split(joint[['geometry','decision']][joint.within(poly)], joint['decision'][joint.within(poly)], test_size=testSplit, random_state=42, shuffle=True, stratify = joint['decision'][joint.within(poly)])\n",
    "nodes = gpd.sjoin(initial, X_train, how='left', op='within')\n",
    "nodes = nodes[~nodes.index.duplicated(keep='first')]\n",
    "nodes.loc[nodes.decision == 'GREEN (inspected) أخضر (تم دراسته)', ['noDmg', 'dmg']] = 1-gb, gb\n",
    "nodes.loc[nodes.decision == 'YELLOW (restricted use) أصفر (لا يصلح للسكن)', ['noDmg', 'dmg']] = 1-yb, yb\n",
    "nodes.loc[nodes.decision == 'RED (unsafe/evacuate) أحمر (غير آمن/للاخلاء)ء', ['noDmg', 'dmg']] = 1-rb, rb\n",
    "\n",
    "# Create edges\n",
    "edges = []\n",
    "\n",
    "# Create edges between geographically adjacent nodes\n",
    "if adjacent:\n",
    "    x, l = len(df), len(nodes)\n",
    "    for i in nodes.index:\n",
    "        if not i % x == x-1: edges.append([i,i+1]) # Pixel to right (edge to left is equivalent to previous edge to right)\n",
    "        if not i > l-x-1: edges.append([i,i+x]) # Pixel below (edge above is accounted for is equivalent to previous edge below)\n",
    "\n",
    "# Create edges between most similar phase change pixels\n",
    "if ifgValues:\n",
    "    edges = edges + np.ndarray.tolist(np.array(kneighbors_graph(np.array(nodes.ifg).reshape(-1,1), neighbours, mode='connectivity', include_self=False).nonzero()).reshape(2,-1).transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visible-static",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.axes[0].get_level_values('x').nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aware-reasoning",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes.geometry.x.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "floral-block",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run belief propagation\n",
    "priors = np.array(nodes[['noDmg','dmg']])\n",
    "beliefs, _ = nc.netconf(np.array(edges),priors,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extraordinary-jurisdiction",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation Metrics\n",
    "\n",
    "# Get y_true vs y_pred for test set\n",
    "y_true = gpd.sjoin(initial, X_test, how='left', op='within').dropna(subset=['decision']).decision.map(decisions)\n",
    "y_pred =  skl.preprocessing.normalize(beliefs[y_true.index], norm='l1')[:,1]\n",
    "\n",
    "# Classification metrics\n",
    "ypClf = skl.preprocessing.binarize(y_pred.reshape(-1, 1), threshold=dmgThresh)\n",
    "print(skm.classification_report(y_true, ypClf , target_names=targets, zero_division=0))\n",
    "\n",
    "# Confusion matrix\n",
    "fig, axs = plt.subplots(1,2, figsize=[14,5])\n",
    "conf = skm.confusion_matrix(y_true, ypClf)\n",
    "axs[0].imshow(conf, interpolation='nearest')\n",
    "axs[0].set_xticks(range(len(targets))), axs[0].set_xticklabels(targets), axs[0].set_yticks(range(len(targets))), axs[0].set_yticklabels(targets)\n",
    "axs[0].set_xlabel('Predicted Class'), axs[0].set_ylabel('True Class'), axs[0].set_title('Confusion Matrix')\n",
    "for i in range(len(targets)): \n",
    "    for j in range(len(targets)): text = axs[0].text(j, i, conf[i, j], ha=\"center\", va=\"center\", color=\"r\")\n",
    "        \n",
    "# Cross entropy / Confidence metrics\n",
    "axs[1].hist(y_pred[(np.array(1-y_true)*y_pred).nonzero()[0]], range = [0,1], bins = 100, label = targets[0], color = 'g', alpha = 0.5)\n",
    "axs[1].hist(y_pred[(np.array(y_true)*y_pred).nonzero()[0]], range = [0,1], bins = 100, label = targets[1], color = 'r', alpha = 0.8)\n",
    "axs[1].set_title('Cross-Entropy loss: {}'.format(skl.metrics.log_loss(y_true, y_pred)))\n",
    "axs[1].legend(title='True Classes', loc='upper right'), axs[1].set_xlabel('Damage Probability'), axs[1].set_ylabel('Number of predictions')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "multiple-leave",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
