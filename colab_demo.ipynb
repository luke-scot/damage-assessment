{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "colab": {
      "name": "colab_demo.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/luke-scot/damage-assessment/blob/main/colab_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "great-barrier"
      },
      "source": [
        "# Confidence-aware belief propagation for multimodal data\n",
        "This notebook runs a demonstration of the belief propagtion (BP) framework initially created for post-disaster damage assessment by Luke Cullen at the University of Cambridge. For development, please see the [Github repository](https://github.com/luke-scot/damage-assessment). Alternatively for further details the full report accompanying this project is available [here](https://drive.google.com/file/d/1IZ3B0m5FrPybTsKMUQ52ExvheMin9WdB/view?usp=sharing).\n",
        "\n",
        "Colab tips - Colab isn't keen on interactions so this demo is less pretty than the [Github demo](https://github.com/luke-scot/damage-assessment/blob/main/demo.ipynb) created in Descartes Labs, but you will have no problems with installing packages. If runtime becomes an issue, make sure you're not running multiple sessions.\n",
        "\n",
        "To run each cell simply press Shift+Enter.\n",
        "\n",
        "## Setup\n",
        "Run the first cell to download the latest version of the demo functions."
      ],
      "id": "great-barrier"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "major-london"
      },
      "source": [
        "%%capture\n",
        "# Clone repository\n",
        "! git clone https://github.com/luke-scot/damage-assessment.git\n",
        "%cd damage-assessment\n",
        "\n",
        "# Install uncommon packages\n",
        "%pip install install rioxarray geopandas ipyleaflet gdown pygeos\n",
        "\n",
        "import colab_interactions as it"
      ],
      "id": "major-london",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "colonial-edward"
      },
      "source": [
        "## Introduction to Damage Assessment application\n",
        "\n",
        "A brief introduction to damage assessment and belief propagation."
      ],
      "id": "colonial-edward"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drawn-agriculture"
      },
      "source": [
        "In the immediate aftermath of a disaster, such as the 4th August 2020 Beirut port explosion, there are 2 priority tasks for recovery efforts:\n",
        "* Search & Rescue - Need to prioritise most damaged area to send reconnaissance teams, and save lives of people trapped.\n",
        "\n",
        "* Damage Assessment - Classify buildings to prevent further casualties and assess humanitarian/reconstruction needs.\n",
        "\n",
        "Both rely on rapid knowledge of building damages. \n",
        "\n",
        "This project explores using Belief Propagation to rapidly assess infrastructure damage by combining all data available into a graph representation of the affected area. I will focus mainly on remote sensing (satellite) data due to its availability and past efficiency in identifying damage. \n",
        "\n",
        "This model brings two new features to automating damage assessments both key to creating actionable information for responders:\n",
        "*   Uncertainty quantification - Hence choice of confidence-aware NetConf algorithm as basis for BP (originally created by Eswaran et al. (2017))\n",
        "*   Multimodality - Graph representation allows us to combine any data, however incomplete or useful, as it becomes available in a post-disaster scenario."
      ],
      "id": "drawn-agriculture"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "indonesian-attitude"
      },
      "source": [
        "## What is Belief Propagation?\n",
        "\n",
        "Before delving in to large-scale spatial applications, take a look at what BP is doing at an interpretable level. This part will show the code as we step through so you can get of taste of the magic that goes on behind close doors in the real application scenario."
      ],
      "id": "indonesian-attitude"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "angry-journalism"
      },
      "source": [
        "Choose your parameters in the first cell and then keep going to see where you end up, nodes unassigned to either class will begin as unknowns. Leave plenty as this is how you'll get to understand what BP is doing."
      ],
      "id": "angry-journalism"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "legendary-reality"
      },
      "source": [
        "# Choose your graph parameters - you can always come back once you understand what these mean\n",
        "nodes = 10\n",
        "zeros = 2 # Nodes in class 0 \n",
        "ones = 2 # Nodes in class 1\n",
        "neighbours = 2 # Edges will be created to this number of nearest neighbours\n",
        "edgeType = 'values' # Nearest neighbours according to 'values' or 'location'\n",
        "cmap = 'RdYlGn' # No need to change unless you're fancying some groovy colours today"
      ],
      "id": "legendary-reality",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "residential-explanation"
      },
      "source": [
        "# Import those handy pre-made functions\n",
        "import random\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "import matplotlib as mpl\n",
        "from netconf import netconf\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.neighbors import kneighbors_graph"
      ],
      "id": "residential-explanation",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "alive-cooperative"
      },
      "source": [
        "# Create a graph and add your nodes\n",
        "G = nx.Graph() # Initialise the graph - nodes have got to go somewhere\n",
        "G.add_nodes_from(range(nodes)) # Nodes going on\n",
        "nx.draw(G, node_size=1500, with_labels=True) # Let's have a look"
      ],
      "id": "alive-cooperative",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "increased-airfare"
      },
      "source": [
        "\"\"\"\n",
        "Good start, now let's add our prior knowledge.\n",
        "\n",
        "We'll randomly assign which nodes are to be in classes 0 and 1, with the rest \n",
        "being ignorant - i.e. 0.5 prior belief.\n",
        "\"\"\"\n",
        "priors = [1]*ones+[0]*zeros+[0.5]*(nodes-(ones+zeros))\n",
        "np.random.shuffle(priors)\n",
        "\n",
        "# Let's draw it again\n",
        "nx.draw(G, node_size=1500, with_labels=True, node_color=priors, cmap=cmap)\n",
        "\n",
        "# Don't worry about these, it's just adding a colorbar to look pretty\n",
        "sm = plt.cm.ScalarMappable(cmap=cmap, norm=plt.Normalize(vmin = 0, vmax=1))\n",
        "c = plt.colorbar(sm)\n",
        "c.set_label('Class 1 probability', fontsize=14)"
      ],
      "id": "increased-airfare",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "announced-yorkshire"
      },
      "source": [
        "\"\"\"\n",
        "We have our prior beliefs! Let's get some edges involved.\n",
        "\n",
        "kneighbours_graph is a function which finds the nearest neighbours to each\n",
        "node according to it's value. The values of our nodes are 0 to n (n being how\n",
        "many nodes you chose) as displayed on each graph\n",
        "\"\"\"\n",
        "# Get edges\n",
        "values = np.array(range(nodes)).reshape(-1,1) # Get our values in a vector\n",
        "edges = kneighbors_graph(values,neighbours,mode='connectivity',include_self=False)\n",
        "\n",
        "# Just a matrix re-shuffle to make the output usable, don't panic\n",
        "edges = np.array(edges.nonzero()).reshape(2,-1).transpose() \n",
        "\n",
        "# Let's take another look\n",
        "nx.draw(G, node_size=1500, with_labels=True, node_color=priors, cmap=cmap, edgelist=edges)\n",
        "c = plt.colorbar(sm)\n",
        "c.set_label('Class 1 probability', fontsize=14)"
      ],
      "id": "announced-yorkshire",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "modern-knight"
      },
      "source": [
        "\"\"\"\n",
        "Ok, here we are, let's fire up the beast!\n",
        "\n",
        "Netconf is implemented in the netconf.py file, feel free to have a browse but there's \n",
        "not much need unless you're an equations enthusiast.\n",
        "\"\"\"\n",
        "priors = np.array(priors).reshape(-1,1) # Just a little matrix shimmy\n",
        "posteriors, _ = netconf(edges,priors, verbose=True) # Here it goes! "
      ],
      "id": "modern-knight",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "advanced-diana"
      },
      "source": [
        "\"\"\"\n",
        "Well, wasn't that exhilirating!\n",
        "Ok, now we'll plot up the priors against the posteriors to see what actually went \n",
        "down.\n",
        "\"\"\"\n",
        "fig, axs = plt.subplots(1, 2, figsize=[15,5])\n",
        "nx.draw(G, node_size=1500, with_labels=True, node_color=priors, cmap=cmap, edgelist=edges, ax=axs[0])\n",
        "c = plt.colorbar(sm, ax=axs[0])\n",
        "c.set_label('Class 1 probability', fontsize=14)\n",
        "\n",
        "nx.draw(G, node_size=1500, with_labels=True, node_color=posteriors, cmap=cmap, edgelist=edges, ax=axs[1])\n",
        "c = plt.colorbar(sm, ax=axs[1])\n",
        "c.set_label('Class 1 probability', fontsize=14)"
      ],
      "id": "advanced-diana",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "handy-aurora"
      },
      "source": [
        "Nice Graphs! So hopefully this short BP demo has given you a glimpse into the world of graph representation and belief propagation. Now, imagine a graph a lot (and I mean A LOT) bigger where each node could represent a 50x50cm square over a city... Daunting? Well that's where we're heading next. Keep scrolling to see how BP can be applied to real-world problems with large-scale spatial data."
      ],
      "id": "handy-aurora"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hungry-proof"
      },
      "source": [
        "## Real-world application\n",
        "Ok, now that you're a belief propagation expert, let's look at some slightly more interesting applications. "
      ],
      "id": "hungry-proof"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "interim-balance"
      },
      "source": [
        "The first cell will give you 3 options:\n",
        "1.   Beirut damage assessment scenario - This is the target application.\n",
        "2.   Houston land classification - This is a demonstration to show how the model performs on spatial data in 'well-behaved' setting.\n",
        "3.   None - Free reign, input whatever you feel like as long as you have a ground truth (shapefile or imagefile) and image data. You can start with the above defaults and adjust from there though if you don't want to be plunged in a the deep end.\n",
        "\n",
        "I would recommend starting with the Houston demonstration (I know it's second \n",
        "on the dropdown) and once you've been through that come back up to play with the Beirut damage assessment which is the real application we are aiming for."
      ],
      "id": "interim-balance"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acute-third"
      },
      "source": [
        "# Run me!\n",
        "defaults = it.get_defaults()"
      ],
      "id": "acute-third",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hungarian-familiar"
      },
      "source": [
        "# Picked your default? Run me to display your inputs.\n",
        "inputs = it.input_parameters(defaults)"
      ],
      "id": "hungarian-familiar",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "distant-virgin"
      },
      "source": [
        "# Please confirm your types before running this one\n",
        "# If it's the first time you've run it for the application - this will download\n",
        "# the data, it should be quick but bare with.\n",
        "download = which_download(inputs) \n",
        "! bash download\n",
        "parameters = model_parameters(inputs)"
      ],
      "id": "distant-virgin",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "honest-headline"
      },
      "source": [
        "# Quick fix for Colab\n",
        "# classAssign = False if ('bxAssign' not in v) or (bxCluster.trait_values()['children'][1].value is True) else [list(i.value) for i in bxAssign.trait_values()['children']]\n",
        "# classNames = False if 'bxClNames' not in v else [i.value for i in bxClNames.trait_values()['children']]\n",
        "#classAssign = False if ('bxAssign' not in v) or (bxCluster.trait_values()['children'][1].value is True) else [\n",
        "classAssign = [['GREEN','LAND'],['YELLOW','RED','TOTAL']]\n",
        "classNames = [['Undamaged', 'Damaged']]\n",
        "parameters.update({'classAssign':classAssign, 'classNames':classNames})"
      ],
      "id": "honest-headline",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "peripheral-turkey"
      },
      "source": [
        "# You only need to run this once (unless you change the area of interest on interactive map)\n",
        "imports = it.import_data(parameters)"
      ],
      "id": "peripheral-turkey",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "deadly-hunger"
      },
      "source": [
        "classified = it.classify_data(imports)"
      ],
      "id": "deadly-hunger",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "constitutional-yemen"
      },
      "source": [
        "output = it.run_bp(classified)"
      ],
      "id": "constitutional-yemen",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aging-default"
      },
      "source": [
        "plots = it.evaluate_output(output)"
      ],
      "id": "aging-default",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "documented-gasoline"
      },
      "source": [
        "it.save_plot(plots, location='results/performancePlot.png')"
      ],
      "id": "documented-gasoline",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "excellent-woman"
      },
      "source": [
        "mapping = it.map_result(plots)"
      ],
      "id": "excellent-woman",
      "execution_count": null,
      "outputs": []
    }
  ]
}