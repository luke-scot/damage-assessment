{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "angry-license",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/luke-scot/damage-assessment/blob/main/colab_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worth-lafayette",
   "metadata": {
    "id": "great-barrier"
   },
   "source": [
    "# Confidence-aware belief propagation for multimodal data\n",
    "This notebook runs a demonstration of the belief propagtion (BP) framework initially created for post-disaster damage assessment by Luke Cullen at the University of Cambridge. For development, please see the [Github repository](https://github.com/luke-scot/damage-assessment). Alternatively for further details, the full report accompanying this project is available [here](https://drive.google.com/file/d/1IZ3B0m5FrPybTsKMUQ52ExvheMin9WdB/view?usp=sharing).\n",
    "\n",
    "To run each cell simply press Shift & Enter simultaneously.\n",
    "\n",
    "## Setup\n",
    "Run the first cell to download the latest version of the demo functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sticky-chaos",
   "metadata": {
    "id": "major-london"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Clone repository\n",
    "! git clone https://github.com/luke-scot/damage-assessment.git\n",
    "%cd damage-assessment\n",
    "\n",
    "# Install uncommon packages\n",
    "%pip install install rioxarray geopandas ipyleaflet gdown pygeos\n",
    "\n",
    "import colab_interactions as it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "addressed-recorder",
   "metadata": {
    "id": "colonial-edward"
   },
   "source": [
    "## Introduction to Damage Assessment application\n",
    "\n",
    "A brief introduction to damage assessment and belief propagation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "portuguese-details",
   "metadata": {
    "id": "drawn-agriculture"
   },
   "source": [
    "In the immediate aftermath of a disaster, such as the 4th August 2020 Beirut port explosion, there are 2 priority tasks for recovery efforts:\n",
    "* Search & Rescue - Need to prioritise most damaged area to send reconnaissance teams, and save lives of people trapped.\n",
    "\n",
    "* Damage Assessment - Classify buildings to prevent further casualties and assess humanitarian/reconstruction needs.\n",
    "\n",
    "Both rely on rapid knowledge of building damages. \n",
    "\n",
    "This project explores using Belief Propagation to rapidly assess infrastructure damage by combining all data available into a graph representation of the affected area. I will focus mainly on remote sensing (satellite) data due to its availability and past efficiency in identifying damage. \n",
    "\n",
    "This model brings two new features to automating damage assessments both key to creating actionable information for responders:\n",
    "*   Uncertainty quantification - Hence choice of confidence-aware NetConf algorithm as basis for BP (originally created by [Eswaran et al. (2017)](https://dhivyaeswaran.github.io/papers/sdm17-netconf.pdf).\n",
    "*   Multimodality - Graph representation allows us to combine any data, however incomplete or useful, as it becomes available in a post-disaster scenario."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pointed-income",
   "metadata": {
    "id": "indonesian-attitude"
   },
   "source": [
    "## What is Belief Propagation?\n",
    "\n",
    "Before delving in to large-scale spatial applications, take a look at what BP is doing at an interpretable level. This part will show the code as we step through so you can get a taste of the magic that goes on behind close doors in the real application scenario."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moving-manufacturer",
   "metadata": {
    "id": "angry-journalism"
   },
   "source": [
    "Choose your parameters in the first cell and then keep going to see where you end up, nodes unassigned to either class will begin as unknowns. Leave plenty as this is how you'll get to understand what BP is doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interested-manhattan",
   "metadata": {
    "id": "legendary-reality"
   },
   "outputs": [],
   "source": [
    "# Choose your graph parameters - you can always come back once you understand what these mean\n",
    "nodes = 12 # Total number of nodes\n",
    "zeros = 2 # Nodes in class 0 \n",
    "ones = 2 # Nodes in class 1\n",
    "neighbours = 2 # Edges will be created to this number of nearest neighbours\n",
    "cmap = 'RdYlGn' # No need to change unless you're fancying some groovy colours today"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cheap-chemistry",
   "metadata": {
    "id": "residential-explanation"
   },
   "outputs": [],
   "source": [
    "# Import those handy pre-made functions\n",
    "import random\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib as mpl\n",
    "from netconf import netconf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import kneighbors_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sharing-increase",
   "metadata": {
    "id": "alive-cooperative"
   },
   "outputs": [],
   "source": [
    "# Create a graph and add your nodes\n",
    "G = nx.Graph() # Initialise the graph - nodes have got to go somewhere\n",
    "G.add_nodes_from(range(nodes)) # Nodes going on\n",
    "pos = nx.spring_layout(G) # Fix the positions of the nodes\n",
    "nx.draw(G, pos=pos, node_size=1500, with_labels=True) # Let's have a look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decimal-bruce",
   "metadata": {
    "id": "increased-airfare"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Good start, now let's add our prior knowledge.\n",
    "\n",
    "We'll randomly assign which nodes are to be in classes 0 and 1, with the rest \n",
    "being ignorant - i.e. 0.5 prior belief.\n",
    "\"\"\"\n",
    "priors = [1]*ones+[0]*zeros+[0.5]*(nodes-(ones+zeros))\n",
    "np.random.shuffle(priors)\n",
    "\n",
    "# Let's draw it again\n",
    "nx.draw(G, pos=pos, node_size=1500, with_labels=True, node_color=priors, cmap=cmap)\n",
    "\n",
    "# Don't worry about these, it's just adding a colorbar to look pretty\n",
    "sm = plt.cm.ScalarMappable(cmap=cmap, norm=plt.Normalize(vmin = 0, vmax=1))\n",
    "c = plt.colorbar(sm)\n",
    "c.set_label('Class 1 probability', fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wanted-arbitration",
   "metadata": {
    "id": "announced-yorkshire"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "We have our prior beliefs! Let's get some edges involved.\n",
    "\n",
    "kneighbours_graph is a function which finds the nearest neighbours to each\n",
    "node according to it's value. The values of our nodes are 0 to n (n being how\n",
    "many nodes you chose) as displayed on each graph\n",
    "\"\"\"\n",
    "# Get edges\n",
    "values = np.array(range(nodes)).reshape(-1,1) # Get our values in a vector\n",
    "edges = kneighbors_graph(values,neighbours,mode='connectivity',include_self=False)\n",
    "\n",
    "# Just a matrix re-shuffle to make the output usable, don't panic\n",
    "edges = np.array(edges.nonzero()).reshape(2,-1).transpose() \n",
    "\n",
    "# Let's take another look\n",
    "nx.draw(G, pos=pos, node_size=1500, with_labels=True, node_color=priors, cmap=cmap, edgelist=edges)\n",
    "c = plt.colorbar(sm)\n",
    "c.set_label('Class 1 probability', fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specific-place",
   "metadata": {
    "id": "modern-knight"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Ok, here we are, let's fire up the beast!\n",
    "\n",
    "Netconf is implemented in the netconf.py file, feel free to have a browse but there's \n",
    "not much need unless you're an equations enthusiast.\n",
    "\"\"\"\n",
    "priors = np.array(priors).reshape(-1,1) # Just a little matrix shimmy\n",
    "posteriors, _ = netconf(edges,priors, verbose=True) # Here it goes! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "introductory-puzzle",
   "metadata": {
    "id": "advanced-diana"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Well, wasn't that exhilirating!\n",
    "Ok, now we'll plot up the priors against the posteriors to see what actually went \n",
    "down.\n",
    "\"\"\"\n",
    "fig, axs = plt.subplots(1, 2, figsize=[15,5]) # Initialise a figure \n",
    "\n",
    "# Let's draw the prior beliefs\n",
    "nx.draw(G, pos=pos, node_size=1500, with_labels=True, node_color=priors, cmap=cmap, edgelist=edges, ax=axs[0])\n",
    "axs[0].set_title('Prior beliefs', fontsize=15)\n",
    "c = plt.colorbar(sm, ax=axs[0])\n",
    "c.set_label('Class 1 probability', fontsize=14)\n",
    "\n",
    "# And now the posterior beliefs\n",
    "nx.draw(G, pos=pos, node_size=1500, with_labels=True, node_color=posteriors, cmap=cmap, edgelist=edges, ax=axs[1])\n",
    "axs[1].set_title('Posterior beliefs', fontsize=15)\n",
    "c = plt.colorbar(sm, ax=axs[1])\n",
    "c.set_label('Class 1 probability', fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "welsh-michael",
   "metadata": {
    "id": "handy-aurora"
   },
   "source": [
    "Nice Graphs! So hopefully this short BP demo has given you a glimpse into the world of graph representation and belief propagation. Now, imagine a graph a lot (and I mean A LOT) bigger where each node could represent a 50x50cm square over a city... Daunting? Well that's where we're heading next. Keep scrolling to see how BP can be applied to real-world problems with large-scale spatial data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "national-strategy",
   "metadata": {
    "id": "hungry-proof"
   },
   "source": [
    "## Real-world application\n",
    "Ok, now that you're a belief propagation expert, let's look at some slightly more interesting applications. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accepted-happening",
   "metadata": {
    "id": "interim-balance"
   },
   "source": [
    "The first cell will give you 3 options:\n",
    "1.   Beirut damage assessment scenario - This is the target application.\n",
    "2.   Houston land classification - This is a demonstration to show how the model performs on spatial data in a 'well-behaved' setting.\n",
    "3.   None - Free reign, input whatever you feel like as long as you have a ground truth (shapefile or imagefile) and image data. You can start with the above defaults and adjust from there though if you don't want to be plunged in a the deep end.\n",
    "\n",
    "I would recommend starting with the Houston demonstration (I know it's second \n",
    "on the dropdown) and once you've been through that come back up to play with the Beirut damage assessment which is the real application I was aiming for in this study.\n",
    "\n",
    "> Colab tips - Unfortunately Colab isn't keen on interactions and doesn't support ipyleaflet, so this demo has less features, and is less pretty, than the real model on [Github](https://github.com/luke-scot/damage-assessment/blob/main/demo.ipynb) created in Descartes Labs. However, you will have no problems with installing packages which is why I've chosen Colab. If runtime becomes an issue, make sure you're not running multiple sessions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "operational-china",
   "metadata": {
    "id": "acute-third"
   },
   "outputs": [],
   "source": [
    "# Run me!\n",
    "defaults = it.get_defaults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "limiting-spoke",
   "metadata": {
    "id": "hungarian-familiar"
   },
   "outputs": [],
   "source": [
    "# Picked your default? Run me to display your inputs.\n",
    "inputs = it.input_parameters(defaults)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "australian-rochester",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import imageio\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import ipywidgets as ipw\n",
    "import ipyleaflet as ipl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as clrs\n",
    "from branca.colormap import linear\n",
    "from ipyleaflet import LayersControl\n",
    "from scipy.interpolate import griddata\n",
    "import folium as fl\n",
    "from branca.element import Template, MacroElement\n",
    "\n",
    "import netconf as nc\n",
    "import plotting as pl\n",
    "import imports as ip\n",
    "import transforms as tr\n",
    "\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sized-genome",
   "metadata": {
    "id": "distant-virgin"
   },
   "outputs": [],
   "source": [
    "\"\"\"Please confirm your types before running this one\n",
    "# If it's the first time you've run it for the application - this will retrieve\n",
    "# the relevant data from Google Drive, it should be quick but bare with.\"\"\"\n",
    "download = it.which_download(inputs) \n",
    "! bash $download\n",
    "parameters = model_parameters(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "annual-judges",
   "metadata": {
    "id": "peripheral-turkey"
   },
   "outputs": [],
   "source": [
    "# You only need to import the data once (do not need to re-run for changing class-edge-node configurations)\n",
    "imports = it.import_data(parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seasonal-dublin",
   "metadata": {
    "id": "deadly-hunger"
   },
   "outputs": [],
   "source": [
    "# Now we'll group the labels into classes dependent on your choices\n",
    "classified = it.classify_data(imports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protective-racing",
   "metadata": {
    "id": "constitutional-yemen"
   },
   "outputs": [],
   "source": [
    "# Ok, we are ready to rumble! Hit the button.\n",
    "output = it.run_bp(classified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "democratic-mistress",
   "metadata": {
    "id": "aging-default"
   },
   "outputs": [],
   "source": [
    "# It's done! Or should be, first let's look at performance metrics.\n",
    "plots = it.evaluate_output(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "marine-prompt",
   "metadata": {
    "id": "documented-gasoline"
   },
   "outputs": [],
   "source": [
    "# Fancy saving the plot? Go for it.\n",
    "it.save_plot(plots, location='results/performancePlot.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "novel-mailman",
   "metadata": {
    "id": "excellent-woman"
   },
   "outputs": [],
   "source": [
    "\"\"\" Ok let's see the final classification map!\n",
    "This is currently ony supported for 2-class classification.\n",
    "For a fully interactive plot you'll have to bite the bullet\n",
    "and get the real model as Colab is not quite upto it unfortunately\"\"\"\n",
    "\n",
    "mapping = it.map_result(plots)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continental-surgery",
   "metadata": {},
   "source": [
    "That's all folks! Scroll back up and have a play around. Or if you're feeling the BP groove, hit it up with your own data!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cultural-composer",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "Hopefully this demo has shown you the real potential of graph-based belief propagation. The uncertainty quantification and multimodality are two very appealing features for any application, notably in the scientific field. \n",
    "I'm always keen to hear of any new applications in graph representation learning. So, even if you didn't like my demo, please drop me a line at lshc3@cam.ac.uk, maybe you can tell me where I'm going wrong!"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "colab_demo.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
