{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "prescribed-thompson",
   "metadata": {},
   "source": [
    "# Belief Propagation from Geo-Located Imagery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "weighted-charter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If new server on Descartes Labs, need to install rioxarray \n",
    "try: import rioxarray\n",
    "except: \n",
    "    %pip install rioxarray\n",
    "    \n",
    "# Import helper functions\n",
    "import imports as ip\n",
    "import netconf as nc\n",
    "import plotting as pl\n",
    "import helper_functions as hf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "tested-drain",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parameter_input():\n",
    "    import ipywidgets as ipw\n",
    "    ## Define variables\n",
    "    # Label imports\n",
    "    layout = {'width': 'max-content'}\n",
    "    display(ipw.HTML(value = f\"<b>{'Label Parameters'}</b>\"))\n",
    "    bxLabel = ipw.Box([ipw.Label(value='Damage Labels: Shapefile - '), ipw.Text(value='./data/beirutDamages.shp', placeholder='damages.shp',  disabled=False,layout=layout),\n",
    "                   ipw.Label(value='Coordinate System - '), ipw.Text(value='EPSG:4326', placeholder='EPSG:4326',  disabled=False,layout=layout),\n",
    "                   ipw.Label(value='Decision Column - '), ipw.Text(value='decision', placeholder='decision',  disabled=False, layout=layout),\n",
    "                   ipw.Label(value='First Word Only - '), ipw.Checkbox(value=False, disabled=False, indent=False)])\n",
    "\n",
    "    bxConf = ipw.Box([ipw.Label(value='Label Confidence ($P_{other label}$, $P_{class}$)'),\n",
    "                      ipw.FloatRangeSlider(value=[0, 1], min=0, max=1, step=0.01, disabled=False, continuous_update=True, orientation='horizontal', readout=True, readout_format='.2f')])\n",
    "    display(bxLabel,bxConf)\n",
    "\n",
    "    # Data imports\n",
    "    display(ipw.HTML(value = f\"<b>{'Data Parameters'}</b>\"))\n",
    "    bxDataTypes = ipw.Box([ipw.Label(value='Enter Data Types:'),\n",
    "                           ipw.Combobox(value='HighRes Imagery', placeholder='Data Type 1', options=['HighRes Imagery','Interferogram','LowRes Imagery'], ensure_option=False, disabled=False,layout=layout),\n",
    "                           ipw.Combobox(value='Interferogram', placeholder='Data Type 2', options=['HighRes Imagery','Interferogram','LowRes Imagery'], ensure_option=False, disabled=False,layout=layout),\n",
    "                           ipw.Combobox(placeholder='Data Type 3', options=['HighRes Imagery','Interferogram','LowRes Imagery'], ensure_option=False, disabled=False,layout=layout),\n",
    "                           ipw.Combobox(placeholder='Data Type 4', options=['HighRes Imagery','Interferogram','LowRes Imagery'], ensure_option=False, disabled=False,layout=layout)])\n",
    "\n",
    "    button1 = ipw.Button(description='Confirm Types', disabled=False, button_style='success', tooltip='Confirm', icon='check')\n",
    "\n",
    "    bxMap = ipw.Box([ipw.Label(value='Latitude - '), ipw.FloatText(value=33.893, placeholder='dd.dddd',  disabled=False,layout=layout),\n",
    "                       ipw.Label(value='Longitude - '), ipw.FloatText(value=35.512, placeholder='dd.dddd',  disabled=False,layout=layout),\n",
    "                       ipw.Label(value='Zoom - '), ipw.IntText(value=14, placeholder='dd.dddd',  disabled=False, layout=layout),\n",
    "                       ipw.Label(value='Standard Test Area - '), ipw.Checkbox(value=False, disabled=False, indent=False)])\n",
    "\n",
    "    display(bxDataTypes)\n",
    "\n",
    "    defFiles = [\"data/highRes/20JUL31_HR_LatLon.tif\",\"data/highRes/20AUG05_HR_LatLon.tif\",\"./data/beirutPrePreExplosionIfg.tif\",\"./data/beirutPrePostExplosionIfg.tif\"]\n",
    "\n",
    "    out1 = ipw.Output()\n",
    "    def on_button1_clicked(b1):\n",
    "        button1.description = 'Confirmed'\n",
    "        with out1:\n",
    "            dataTypes = [i.value.split(' ')[0] for i in bxDataTypes.trait_values()['children'][1:] if len(i.value) > 0]\n",
    "            for i in range(len(dataTypes)):\n",
    "                try: globals()['bxfile'+str(i)] = ipw.Box([ipw.Label(value=dataTypes[i]+' File Locations: Pre -'), ipw.Text(value=defFiles[2*i], placeholder=dataTypes[i]+'PreFile', disabled=False),\n",
    "                         ipw.Label(value=' Post -'), ipw.Text(value=defFiles[2*i+1], placeholder=dataTypes[i]+'PostFile', disabled=False)])\n",
    "                except: globals()['bxfile'+str(i)] = ipw.Box([ipw.Label(value=dataTypes[i]+' File Locations: Pre -'), ipw.Text(placeholder='Enter file path', disabled=False),\n",
    "                         ipw.Label(value=' Post -'), ipw.Text(placeholder='Enter file path', disabled=False)])\n",
    "                display(globals()['bxfile'+str(i)])\n",
    "                v['bxfile'+str(i)] = globals()['bxfile'+str(i)]\n",
    "            display(ipw.HTML(value = f\"<b>{'Map Properties'}</b>\"))\n",
    "            display(bxMap)\n",
    "            \n",
    "    button1.on_click(on_button1_clicked)\n",
    "    display(ipw.VBox([button1, out1]))\n",
    "    \n",
    "    v = {}\n",
    "    v.update({'bxLabel':bxLabel,'bxConf':bxConf,'bxDataTypes':bxDataTypes,'bxMap':bxMap})\n",
    "\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "median-updating",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as ipw\n",
    "def label_map(v):\n",
    "    # Extract parameter values from widgets\n",
    "    v['groundTruth'], v['crs'], v['cn'], v['splitString'] =  [i.value for i in v['bxLabel'].trait_values()['children'][1::2]]\n",
    "    v['confidence'] = list(v['bxConf'].trait_values()['children'][1].value)\n",
    "    v['dataTypes'] = [i.value.split(' ')[0] for i in v['bxDataTypes'].trait_values()['children'][1:] if len(i.value) > 0]\n",
    "    for j in range(len(v['dataTypes'])):\n",
    "        v['preFile'+str(j)], v['postFile'+str(j)] = [i.value for i in v['bxfile'+str(j)].trait_values()['children'][1::2]]\n",
    "    v['lat'], v['lon'], v['zoom'], v['stdTest'] = [i.value for i in v['bxMap'].trait_values()['children'][1::2]]\n",
    "\n",
    "    ## Import Labels and combine\n",
    "    labels = ip.shape_to_gdf(v['groundTruth'], v['splitString'], v['cn'], crs=v['crs'])\n",
    "\n",
    "    # Display map of assessments upon which to draw Polygon for analysis\n",
    "    m1 = pl.create_map(v['lat'], v['lon'], v['zoom'])\n",
    "    m1 = pl.plot_assessments(labels, m1)\n",
    "    m1, testPoly = pl.draw_polygon(labels, m1, v['stdTest'])\n",
    "    display(m1)\n",
    "    v['labels'], v['testPoly'] = labels, testPoly\n",
    "    return v\n",
    "\n",
    "def model_parameters(v):\n",
    "    layout = {'width': 'max-content'}\n",
    "    display(ipw.HTML(value = f\"<h3>{'Model Parameters'}</h3>\"))\n",
    "    display(ipw.HTML(value = f\"<b>{'Class Properties'}</b>\"))\n",
    "    # Display default classes from labels\n",
    "    unique = v['labels'][v['cn']].unique()\n",
    "    display(ipw.HTML(value = \"Label Classes - \"f\"{str(unique)}\"))\n",
    "    # Ask for number of classes to use\n",
    "    bxNClasses = ipw.Box([ipw.Label(value='Classes for Model - '), ipw.Dropdown(options=list(range(2,len(unique)+1)),value=max(list(range(len(unique)+1))),disabled=False)])   \n",
    "    display(bxNClasses)\n",
    "    \n",
    "    # Nodes\n",
    "    bxNodes = ipw.Box([ipw.Label(value='Maximum nodes - Sampling occurs if < pixel number: '), ipw.IntText(value=20000, placeholder='20000',  disabled=False, step=1000, layout=layout)])\n",
    "\n",
    "    # Edges\n",
    "    # Neighbours for each data type\n",
    "    bxEdges = ipw.Box([ipw.Label(value='Neighbours - Edges to nearest values for each node: '), ipw.Box([ipw.IntText(value=3, placeholder='edges', description=str(i)+' - ', disabled=False, layout=layout) for i in v['dataTypes']])])\n",
    "    # Geographical neighbours\n",
    "    bxAdjacent = ipw.Box([ipw.Label(value='Geographical Edges - '), ipw.Checkbox(value=False, disabled=False, indent=False, layout=layout), ipw.Label(value='Geographical Neighbours - '), ipw.IntText(value=4, placeholder='edges',  disabled=False, layout=layout)])\n",
    "            \n",
    "    # Once confirmed then display classification options\n",
    "    button3 = ipw.Button(description='Confirm Classes', disabled=False, button_style='success', tooltip='Confirm', icon='check')\n",
    "    out3 = ipw.Output()\n",
    "    def on_button3_clicked(b3):\n",
    "        button3.description = 'Confirmed'\n",
    "        with out3:\n",
    "            # Read number of classes\n",
    "            nClasses = bxNClasses.trait_values()['children'][1].value\n",
    "            # If class grouping required propose options\n",
    "            if nClasses < len(unique):\n",
    "                # Opt to use clustering or not\n",
    "                bxCluster = ipw.Box([ipw.Label(value='Use class clustering - Uncheck to assign classes below:'), ipw.Checkbox(value=True, disabled=False, indent=False)])\n",
    "                # Assign each value to a class\n",
    "                bxAssign = ipw.Box([ipw.SelectMultiple(options=unique, rows=len(unique), description='Class '+str(i)+':', disabled=False) for i in range(nClasses)])\n",
    "                # Edit class names if desired\n",
    "                bxClNames = ipw.Box([ipw.Text(value=str(i), placeholder='Enter Class Name', description='Class '+str(i)+':', disabled=False) for i in range(nClasses)])\n",
    "                display(bxCluster, bxAssign)\n",
    "                display(ipw.HTML(value = \"Edit Class Names:\"))\n",
    "                display(bxClNames)\n",
    "                \n",
    "                v.update({'bxCluster':bxCluster, 'bxAssign':bxAssign, 'bxClNames':bxClNames})\n",
    "                # PCA options if needed in future\n",
    "                # pca, pcaComps, meanCluster = False, 2, True # Clustering properties if used\n",
    "                \n",
    "            # Nodes\n",
    "            display(ipw.HTML(value = f\"<b>{'Node Properties'}</b>\"))\n",
    "            display(bxNodes)\n",
    "\n",
    "            # Edges\n",
    "            display(ipw.HTML(value = f\"<b>{'Edge Properties'}</b>\"))\n",
    "            display(bxEdges,bxAdjacent)\n",
    "                \n",
    "    button3.on_click(on_button3_clicked)\n",
    "    display(ipw.VBox([button3, out3]))\n",
    "    v.update({'bxNClasses':bxNClasses,'bxNodes':bxNodes,'bxEdges':bxEdges,'bxAdjacent':bxAdjacent})\n",
    "    \n",
    "    return v   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "flexible-citizenship",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Imports\n",
    "# Reproject data to used crs\n",
    "def reproject_data(v):\n",
    "    print(\"------Checking Coordinate Systems-------\")\n",
    "    for i in range(len(v['dataTypes'])):\n",
    "        if v['crs'] not in ip.get_crs(v['postFile'+str(i)]):\n",
    "            v['postFile'+str(i)] = ip.conv_coords([v['postFile'+str(i)]], [\"data/PostConv\"+str(i)+\".tif\"], v['crs'])[0]\n",
    "            if v['preFile'+str(i)]: v['preFile'+str(i)] = ip.conv_coords(v['preFile'+str(i)], [\"data/PreConv\"+str(i)+\".tif\"], v['crs'])[0]\n",
    "    print(\"------Finished Checking Coordinate Systems-------\")\n",
    "    return v\n",
    "\n",
    "def import_data(v):\n",
    "    for i in v.keys(): globals()[i] = v[i]\n",
    "    # Retrieve Data from inputs\n",
    "    max_nodes = bxNodes.trait_values()['children'][1].value\n",
    "    neighbours = [i.value for i in bxEdges.trait_values()['children'][1].trait_values()['children']]\n",
    "    adjacent, geoNeighbours = [i.value for i in bxAdjacent.trait_values()['children'][1::2]]\n",
    "    nClasses = bxNClasses.trait_values()['children'][1].value\n",
    "    classAssign = False if 'bxAssign' not in v or bxAssign.trait_values()['children'][1].value else [list(i.value) for i in bxAssign.trait_values()['children']]\n",
    "    classNames = False if 'bxClNames' not in v else [i.value for i in bxClNames.trait_values()['children']]\n",
    "    v.update({'max_nodes':max_nodes, 'neighbours':neighbours, 'adjacent':adjacent, 'geoNeighbours':geoNeighbours, 'nClasses':nClasses, 'classAssign':classAssign, 'classNames':classNames})\n",
    "    # Reproject Data if necessary\n",
    "    v = reproject_data(v)\n",
    "    \n",
    "    # Import Files\n",
    "    print(\"------Importing Data Files---------\")\n",
    "    # Import first data type\n",
    "    df, crop = ip.img_to_df(postFile0, testPoly, crs=crs)\n",
    "    if preFile0:\n",
    "        preDf, _ = ip.img_to_df(preFile0, testPoly, crs=crs)\n",
    "        df -= preDf\n",
    "\n",
    "    # Import other data types\n",
    "    if len(dataTypes) > 1:\n",
    "        crop.rio.to_raster(\"croptemp.tif\")\n",
    "        for i in range(1, len(dataTypes)):\n",
    "            ip.resample_tif(globals()['postFile'+str(i)], testPoly, 'posttemp'+str(i)+'.tif')\n",
    "            globals()['dataArray'+str(i)] = ip.tif_to_array('posttemp'+str(i)+'.tif', 'resample')\n",
    "            if globals()['preFile'+str(i)]: \n",
    "                ip.resample_tif(globals()['preFile'+str(i)], testPoly, 'pretemp'+str(i)+'.tif')\n",
    "                globals()['dataArray'+str(i)] -= ip.tif_to_array('pretemp'+str(i)+'.tif', 'resample')\n",
    "        ip.del_file_endings(\".\", \"temp.tif\")\n",
    "\n",
    "    # Concatenate data types\n",
    "    data = df.copy()\n",
    "    for j in range(1, len(dataTypes)): data[dataTypes[j]]=globals()['dataArray'+str(j)].flatten()\n",
    "    data.dropna(inplace=True)\n",
    "\n",
    "    # Sample data and create geodataframe\n",
    "    gdf = ip.get_sample_gdf(data, max_nodes, crs)\n",
    "    v.update({'max_nodes':max_nodes, 'gdf':gdf, 'typesUsed':[list(df.columns.values), dataTypes[1:]]})\n",
    "    print(\"------Finished Data Import---------\")\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "honey-fellowship",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Assign Label classes to data\n",
    "def classify_data(v):\n",
    "    print(\"------Data Classification---------\")\n",
    "    for i in v.keys(): globals()[i] = v[i]\n",
    "    nClasses = v['nClasses']\n",
    "    defClasses, labelsUsed, dataUsed = len(labels[cn].unique()), labels.to_crs(crs).copy(), gdf.copy() # Default classes from labels\n",
    "    usedNames = labels[cn].unique() if nClasses==defClasses or nClasses is False else classNames\n",
    "    initial = hf.init_beliefs(dataUsed, classes=nClasses, columns=usedNames, crs=crs) # Initial class value for each data pixel\n",
    "\n",
    "    if not nClasses or nClasses == defClasses: \n",
    "        nClasses = defClasses # If default classes used\n",
    "        classesUsed = usedNames.copy()\n",
    "    elif nClasses > defClasses: raise NameError('Cannot assign more classes than in original data') # If invalid input\n",
    "    elif nClasses < defClasses: # Perform class grouping\n",
    "        if not classAssign: # Perform clustering\n",
    "            # Assign labels to each pixel\n",
    "            allPixels = hf.create_nodes(initial, labelsUsed[['geometry',cn]][labelsUsed.within(hf.get_polygon(testPoly, conv=True))])\n",
    "            # Run PCA if set to True\n",
    "            #X = hf.run_PCA(dataUsed[typesUsed[0]].values.transpose(), pcaComps).components_.transpose() if pca else dataUsed[typesUsed[0]]\n",
    "            X = dataUsed[typesUsed[0]]\n",
    "            # Run clustering\n",
    "            meanCluster = True\n",
    "            kmeans, clusterClasses, initLabels = hf.run_cluster(X.iloc[allPixels[cn].dropna().index].values.reshape(-1,len(typesUsed[0])), allPixels[cn].dropna(), meanCluster, nClasses)\n",
    "            print('Clustered classes:{} , original classes:{}'.format(clusterClasses, initLabels))\n",
    "            # Create groups of classes\n",
    "            classesUsed = []\n",
    "            for j in range(nClasses): classesUsed.append([initLabels[i] for i, x in enumerate(list(clusterClasses)) if x==j])\n",
    "        else: \n",
    "            classesUsed = classAssign\n",
    "            #used = [i in flatten_list(classesUsed) for i in labelsUsed[cn]]\n",
    "            initial = hf.init_beliefs(dataUsed, classes=nClasses, columns=usedNames, crs=crs)\n",
    "\n",
    "        # Assign labels for each pixel after clustering\n",
    "        labelsUsed[cn] = hf.group_classes(labelsUsed[cn], classesUsed)\n",
    "    v.update({'labelsUsed':labelsUsed,'initial':initial, 'usedNames':usedNames, 'classesUsed':classesUsed})\n",
    "    print(\"------Finished Data Classification---------\")\n",
    "    return v\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "descending-crown",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_bp(v):\n",
    "    for i in v.keys(): globals()[i] = v[i]\n",
    "    # Split train/test set for located nodes\n",
    "    X_train, X_test, y_train, y_test = hf.train_test_split(labelsUsed, cn, hf.get_polygon(testPoly, conv=True))\n",
    "\n",
    "    # Create nodes\n",
    "    nodes = hf.create_nodes(initial, X_train)\n",
    "\n",
    "    # Assign prior beliefs from assessments\n",
    "    priors = hf.prior_beliefs(nodes, beliefColumns = initial.columns[-nClasses:], classNames=classNames, column = cn)\n",
    "\n",
    "    # Create edges\n",
    "    edges = hf.create_edges(nodes, adjacent=adjacent, geo_neighbors=geoNeighbours, values=typesUsed, neighbours=neighbours)\n",
    "    \n",
    "    # Run belief propagation\n",
    "    beliefs, _ = nc.netconf(edges,priors,verbose=True,limit=1e-3)\n",
    "    \n",
    "    v.update({'X_train':X_train, 'X_test':X_test, 'nodes':nodes, 'priors':priors, 'edges':edges,'beliefs':beliefs})\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "superb-hawaii",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_output(v):\n",
    "    for i in v.keys(): globals()[i] = v[i]\n",
    "    # Evaluation Metrics\n",
    "    # Get y_true vs y_pred for test set\n",
    "    y_true, y_pred = hf.get_labels(initial, X_test, beliefs, column=cn)\n",
    "\n",
    "    # Classification metrics\n",
    "    yp_clf, classes = hf.class_metrics(y_true, y_pred, classes=usedNames, orig=classNames)\n",
    "\n",
    "    fig, axs = pl.create_subplots(1,2, figsize=[14,5])\n",
    "\n",
    "    # Confusion matrix\n",
    "    axs = pl.confusion_matrix(axs, y_true, yp_clf, classes if len(labels[cn].unique()) == nClasses else list(range(nClasses)))\n",
    "\n",
    "    # Cross entropy / Confidence metrics\n",
    "    if nClasses == 2: axs = pl.cross_entropy_metrics(axs, y_true, y_pred[:,1].reshape(-1,1), classes)\n",
    "    else: axs[1] = pl.cross_entropy_multiclass(axs[1], y_true, y_pred)\n",
    "\n",
    "    pl.show_plot()\n",
    "    \n",
    "    v.update({'y_true':y_true, 'y_pred':y_pred, 'yp_clf':yp_clf, 'classes':classes, 'fig':fig})\n",
    "    \n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "random-encounter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save figure\n",
    "def save_plot(v, location=False):\n",
    "    for i in v.keys(): globals()[i] = v[i]\n",
    "    if location: pl.save_plot(fig, location)\n",
    "    else: pl.save_plot(fig, 'results/Beirut_UN_nd{}_cls{}{}_neighbours{}{}_std{}_adj{}{}'.format(str(len(nodes)),str(nClasses),str(classesUsed),\n",
    "                                                                                          str(dataTypes),str(neighbours),str(stdTest),\n",
    "                                                                                          str(adjacent),str(geoNeighbours)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "medieval-reality",
   "metadata": {},
   "source": [
    "__________\n",
    "Let's begin with the input parameters. These include the label file, confidence in the labels and the data types we will use. Once we confirm the data types we will be asked for paths to the files containing the imagery. Post-event must be provided but pre-event is optional. If a pre-event image is provided the data used will be the difference between the images which contains more information than the post event image alone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "brutal-providence",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc00872068114e60ba183f4137d3888e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<b>Label Parameters</b>')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce5c1efeaae24f1a90193551bb51363d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Box(children=(Label(value='Damage Labels: Shapefile - '), Text(value='./data/beirutDamages.shp', layout=Layout…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "345c742c2dd24da6b5f533e8a7f42bbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Box(children=(Label(value='Label Confidence ($P_{other label}$, $P_{class}$)'), FloatRangeSlider(value=(0.0, 1…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66cc2f0b9eb14a2f9bfe7151965b4e80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<b>Data Parameters</b>')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06a5e00225b04f8ea3d8688c326f4420",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Box(children=(Label(value='Enter Data Types:'), Combobox(value='HighRes Imagery', layout=Layout(width='max-con…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf5b3275e75444a787b89cf5168515c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Button(button_style='success', description='Confirm Types', icon='check', style=ButtonStyle(), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "v1 = parameter_input()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collectible-jacob",
   "metadata": {},
   "source": [
    "__________\n",
    "Now let's load up the map of our ground labels and define an area for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "adapted-looking",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ff8216608b341de91861822bcf87450",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[33.893, 35.512], controls=(ZoomControl(options=['position', 'zoom_in_text', 'zoom_in_title', 'zoom…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "v2 = label_map(v1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "linear-thumbnail",
   "metadata": {},
   "source": [
    "______\n",
    "Now we'll pick the model parameter to run on the data from the selected area. If we wish to group classes together we will also be offered some clustering options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "sharp-relaxation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f6c3ada1ab546429452bbfe740a5fae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<h3>Model Parameters</h3>')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7318c784ba7495fa812ce56bcf3e6b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<b>Class Properties</b>')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "006149e2c8f94109ac9fcc90705e320f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value=\"Label Classes - ['GREEN' 'YELLOW' 'LAND' 'RED' 'TOTAL']\")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5346ff8479ff4dc2b625222d4a1bae35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Box(children=(Label(value='Classes for Model - '), Dropdown(index=3, options=(2, 3, 4, 5), value=5)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2849a1b631424b9c8088b265fde8fad9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Button(button_style='success', description='Confirm Classes', icon='check', style=ButtonStyle()…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "v3 = model_parameters(v2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electric-runner",
   "metadata": {},
   "source": [
    "________\n",
    "Now we have all the parameters for the model, let's import and classify the data according to our selections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "geological-encyclopedia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Checking Coordinate Systems-------\n",
      "------Finished Checking Coordinate Systems-------\n",
      "------Importing Data Files---------\n",
      "data/highRes/20AUG05_HR_LatLon.tif read completed.\n",
      "data/highRes/20JUL31_HR_LatLon.tif read completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/IPython/core/async_helpers.py:68: SerializationWarning: saving variable None with floating point data as an integer dtype without any _FillValue to use for NaNs\n",
      "  coro.send(None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/beirutPrePostExplosionIfg.tif read completed.\n",
      "./data/beirutPrePreExplosionIfg.tif read completed.\n",
      "------Finished Data Import---------\n",
      "------Data Classification---------\n",
      "------Finished Data Classification---------\n"
     ]
    }
   ],
   "source": [
    "v4 = import_data(v3)\n",
    "v5 = classify_data(v4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spoken-cassette",
   "metadata": {},
   "source": [
    "____________\n",
    "OK, the data is formatted the model parameters are all checked. Let's build the graph of nodes & edges and run the belief propagation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cubic-literature",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodes: 20000, Edges: 120000\n",
      "It\tLoss\tLabel change\n",
      "\n",
      "0\t1.55548e+00\t\t0\n",
      "\n",
      "1\t6.06427e-02\t\t0\n",
      "\n",
      "2\t3.68523e-01\t\t0\n",
      "\n",
      "3\t1.41269e-02\t\t0\n",
      "\n",
      "4\t8.72185e-02\t\t0\n",
      "\n",
      "5\t6.10914e-03\t\t0\n",
      "\n",
      "6\t2.08523e-02\t\t0\n",
      "\n",
      "7\t2.48441e-03\t\t0\n",
      "\n",
      "8\t5.03666e-03\t\t0\n",
      "\n",
      "9\t8.37731e-04\t\t0\n",
      "\n",
      "Time elapsed: 7.210722208023071 seconds\n"
     ]
    }
   ],
   "source": [
    "v6 = run_bp(v5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "muslim-terrain",
   "metadata": {},
   "source": [
    "_____\n",
    "Now let's use the test set to evaluate the effectiveness of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "saving-removal",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Mix of label input types (string and number)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-0bce299d2db2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mv7\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-d6f654dbf12d>\u001b[0m in \u001b[0;36mevaluate_output\u001b[0;34m(v)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# Classification metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0myp_clf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0musedNames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclassNames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_subplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m14\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/damage-assessment/helper_functions.py\u001b[0m in \u001b[0;36mclass_metrics\u001b[0;34m(y_true, y_pred, classes, orig, threshold)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0;31m#     print(classes)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;31m#     if len(classes)==2: yp_clf = skl.preprocessing.binarize(y_pred[:,1].reshape(-1,1), threshold=threshold)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mskl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myp_clf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0morig\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0morig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzero_division\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0myp_clf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mclassification_report\u001b[0;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[1;32m   1973\u001b[0m     \u001b[0mlabels_given\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1974\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1975\u001b[0;31m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munique_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1976\u001b[0m         \u001b[0mlabels_given\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1977\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36munique_labels\u001b[0;34m(*ys)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;31m# Check that we don't mix string type with number type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mys_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Mix of label input types (string and number)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mys_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Mix of label input types (string and number)"
     ]
    }
   ],
   "source": [
    "v7 = evaluate_output(v6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "designed-penetration",
   "metadata": {},
   "source": [
    "Want to save the plot? Run the cell below. If you want to specify a location replace the False boolean with the filepath."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fantastic-parcel",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_plot(v7, location=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "freelance-drive",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Visualise spatial results\n",
    "fig, axs = pl.create_subplots(2,2,figsize=[15,12])\n",
    "\n",
    "prePlot = pl.belief_plot(nodes, axs[0,0], 'RED', normalise=False)\n",
    "postPlot = pl.belief_plot(nodes, axs[0,1], beliefs, normalise=True)\n",
    "assessPlt = joint.loc[joint.within(poly)].plot(ax=axs[1,0], column='decision',cmap='RdYlGn_r')\n",
    "ifgPlot = (pl.cropped_ifg(ifgPreFile,testPoly)-pl.cropped_ifg(ifgPostFile,testPoly)).plot(ax=axs[1,1])\n",
    "prePlot.set_title('A priori damage likelihood'), postPlot.set_title('Updated damage likelihood'), assessPlt.set_title('Damage Assessments')\n",
    "\n",
    "pl.show_plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
